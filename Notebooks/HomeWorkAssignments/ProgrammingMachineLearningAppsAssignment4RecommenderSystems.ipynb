{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b05b3c3d",
   "metadata": {},
   "source": [
    "### In this notebook, we shall use a modified version of the item-based Recommender algorithm from Ch.14 of Machine Learning in Action and use it on joke ratings data based on Jester Online joke Recommender System.\n",
    "### The data set contains two files. The file \"modified_jester_data.csv\" contains the ratings on 100 jokes by 1000 users (each row is a user profile). The ratings have been normalized to be between 1 and 21 (a 20-point scale), with 1 being the lowest rating. A zero indicated a missing rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be58a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary packages.\n",
    "import numpy as np\n",
    "from numpy import linalg as la # this is the package that doesthe factorization for us \n",
    "import pandas as pd\n",
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b9aced",
   "metadata": {},
   "source": [
    "## a. Load the joke ratings data and joke test data into the appropriate data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e63b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jokes(file):\n",
    "    jokes = np.genfromtxt(file, delimiter=',', dtype=str)\n",
    "    jokes = np.array(jokes[:,1])\n",
    "    return jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26796755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileName = r'../../data/jokes.csv'\n",
    "jokes = load_jokes(fileName)\n",
    "jokes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364c3d7d",
   "metadata": {},
   "source": [
    "<p>Since we don't need the index, the first column needs to be ignored.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0b56ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jokes = np.array(jokes[:, 1])\n",
    "# print(jokes.shape)\n",
    "# jokes[0:2] # display the two records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa5b7d",
   "metadata": {},
   "source": [
    "<p>The jokes numpy array contains 100 joke ids mapped to the actual text of the jokes. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34798d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the modified jester data \n",
    "modified_jester_data  = np.genfromtxt('../../data/modified_jester_data.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3defaa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_jester_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b89922",
   "metadata": {},
   "source": [
    "<p>The modified_jester_data contains ratings on 100 jokes by 1000 users where each row is a user profile.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "401b95b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.18, 19.79,  1.34,  2.84,  3.48,  2.5 ,  1.15, 15.17,  2.02,\n",
       "         6.24,  2.5 ,  4.25,  3.82, 19.45,  3.82,  3.48,  3.57,  1.19,\n",
       "         1.15,  1.15,  1.63, 12.5 ,  6.63,  1.19,  2.5 , 12.12, 18.82,\n",
       "        13.86, 20.13,  3.57, 13.14,  6.92,  1.92, 18.82, 16.05, 15.95,\n",
       "         1.83,  2.6 ,  2.6 ,  2.6 ,  2.89,  1.87,  1.97,  1.92,  3.86,\n",
       "         4.74, 14.79, 10.9 , 14.93, 15.13,  2.31,  3.86, 14.2 , 19.3 ,\n",
       "         6.44, 11.92,  1.87,  1.58, 13.82,  2.36, 19.59, 14.59,  4.16,\n",
       "         1.97, 13.82,  9.64,  1.92, 19.3 , 16.68,  6.19,  0.  ,  0.  ,\n",
       "         0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.58,  0.  ,  0.  ,  0.  ,\n",
       "         3.28,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        13.82,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  5.37,  0.  ,  0.  ,\n",
       "         0.  ],\n",
       "       [15.08, 10.71, 17.36, 15.37,  8.62,  1.34, 10.27,  5.66, 19.88,\n",
       "        20.22, 17.75, 19.64, 15.42, 18.43, 15.56, 10.03, 15.66, 10.32,\n",
       "        14.3 ,  9.79, 11.87, 19.64, 19.35, 20.17, 11.05, 18.57, 15.71,\n",
       "        11.87, 10.61, 17.99, 17.5 , 10.08, 18.14, 20.03,  9.2 , 11.73,\n",
       "        18.09, 14.4 , 10.13, 18.91, 18.82,  7.17, 19.64, 19.98,  6.68,\n",
       "         7.8 ,  6.1 , 10.08,  9.54, 14.64, 14.16, 20.03, 11.97,  9.69,\n",
       "         4.5 ,  7.8 , 19.64,  8.86, 11.1 , 20.03,  4.3 ,  7.65,  1.97,\n",
       "        15.47, 15.08,  7.17, 19.74, 12.12, 11.78, 18.52,  6.  , 13.77,\n",
       "        19.3 , 18.77, 18.33, 17.21, 18.72, 19.98, 19.64, 19.2 , 14.93,\n",
       "        15.85, 15.85, 17.07, 19.98, 15.51, 10.95, 14.69, 15.56, 11.58,\n",
       "        13.82,  6.05, 10.71, 18.86, 10.81,  8.86, 14.06, 11.34,  6.68,\n",
       "        12.07],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  , 20.03, 20.27, 20.03, 20.27,  0.  ,\n",
       "         0.  , 18.33, 18.57, 20.37, 17.17,  4.64,  4.11,  3.14, 20.03,\n",
       "        20.03, 20.03, 18.28,  0.  , 19.25,  0.  ,  0.  , 18.48, 18.28,\n",
       "        18.28, 19.93,  0.  , 17.17, 18.28,  0.  ,  0.  , 19.98, 18.33,\n",
       "         0.  , 17.17, 20.08, 18.33, 18.52, 20.27, 20.27,  0.  , 20.27,\n",
       "         0.  , 17.17, 18.33, 20.08, 18.28,  0.  ,  0.  , 18.28, 18.33,\n",
       "         0.  , 18.23,  0.  ,  0.  ,  0.  , 20.27, 17.46, 18.28,  0.  ,\n",
       "         0.  , 18.04, 18.28,  0.  , 18.28, 19.25,  0.  ,  0.  ,  0.  ,\n",
       "         0.  ,  0.  ,  0.  , 19.93,  0.  ,  0.  ,  0.  , 20.08,  0.  ,\n",
       "         0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  , 20.03,\n",
       "         0.  ,  0.  ,  0.  , 20.08,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "         0.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_jester_data[0:3] # first three records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16626c1",
   "metadata": {},
   "source": [
    "## b. Complete the definition for the function \"test\". This function iterates over all users and for each performs evaluation (by calling the provided \"cross_validate_user\" function), and returns the error information necessary to compute Mean Absolute Error (MAE). Use this function to perform evaluation (wiht 20% test-ratio for each user) comparing MAE results using standard item-based collaborative filtering (based on the rating prediction function \"standEst\") with results using the SVD-based version of the rating item-based CF (using \"svdEst\" as the prediction engine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a274d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecludSim(inA,inB):\n",
    "    return 1.0 / (1.0 + la.norm(inA - inB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de031375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsSim(inA,inB):\n",
    "    if len(inA) < 3 :\n",
    "        return 1.0\n",
    "    return 0.5 + 0.5 * np.corrcoef(inA, inB, rowvar = 0)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31f3aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosSim(inA,inB):\n",
    "    num = float(inA.T * inB)\n",
    "    denom = la.norm(inA)*la.norm(inB)\n",
    "    return 0.5 + 0.5 * (num / denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3c0d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standEst(dataMat, user, simMeas, item):\n",
    "    \"\"\"Item-based recommendation engine:\n",
    "    calculates the estimated rating a user would give an item for a given similarity measure\"\"\"\n",
    "    n = np.shape(dataMat)[1] # number of items in the data set.\n",
    "    simTotal = 0.0; ratSimTotal = 0.0 # initialize the two varaibles that will be used to calculate the estimated rating.\n",
    "    for j in range(n): # loop over every item in the row\n",
    "        userRating = dataMat[user,j]\n",
    "        if userRating == 0:\n",
    "            continue          # if an item is rated zero, it means that the user hasn't rated it and you will skipt it\n",
    "        overLap = np.nonzero(np.logical_and(dataMat[:,item]>0, \\\n",
    "                                      dataMat[:,j]>0))[0]\n",
    "        if len(overLap) == 0:\n",
    "            similarity = 0\n",
    "        else:\n",
    "            similarity = simMeas(dataMat[overLap,item], \\\n",
    "                                   dataMat[overLap,j])\n",
    "        #print 'the %d and %d similarity is: %f' % (item, j, similarity)\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return ratSimTotal/simTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51512d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svdEst(dataMat, user, simMeas, item):\n",
    "    \"\"\"This function creates an estimated rating for a given item for a given user. \n",
    "    This function performs SVD  on the data set\"\"\"\n",
    "    n = np.shape(dataMat)[1]\n",
    "    simTotal = 0.0; ratSimTotal = 0.0\n",
    "    data=np.mat(dataMat)\n",
    "    U,Sigma,VT = la.svd(data) # perform SVD on the data set\n",
    "    Sig4 = np.mat(np.eye(4)*Sigma[:4]) #arrange Sig4 into a diagonal matrix\n",
    "    xformedItems = data.T * U[:,:4] * Sig4.I  #create transformed items\n",
    "    for j in range(n):\n",
    "        userRating = data[user,j]\n",
    "        if userRating == 0 or j==item:\n",
    "            continue\n",
    "        similarity = simMeas(xformedItems[item,:].T, xformedItems[j,:].T) # we calcuate matrices in alower dimension space.\n",
    "        #print 'the %d and %d similarity is: %f' % (item, j, similarity)\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return ratSimTotal/simTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b572334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is not needed for Assignment 4, but may be useful for experimentation\n",
    "def recommend(dataMat, user, N=3, simMeas=cosSim, estMethod=standEst):\n",
    "    unratedItems = np.nonzero(dataMat[user,:].A==0)[1] #find unrated items \n",
    "    if len(unratedItems) == 0: return 'you rated everything'\n",
    "    itemScores = []\n",
    "    for item in unratedItems:\n",
    "        estimatedScore = estMethod(dataMat, user, simMeas, item)\n",
    "        itemScores.append((item, estimatedScore))\n",
    "    return sorted(itemScores, key=lambda jj: jj[1], reverse=True)[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31c45172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs evaluatoin on a single user based on the test_ratio\n",
    "# For example, with test_ratio = 0.2, a randomly selected 20 percent of rated \n",
    "# items by the user are withheld and the rest are used to estimate the withheld ratings\n",
    "\n",
    "def cross_validate_user(dataMat, user, test_ratio, estMethod=standEst, simMeas=pearsSim):\n",
    "    number_of_items = np.shape(dataMat)[1]\n",
    "    rated_items_by_user = np.array([i for i in range(number_of_items) if dataMat[user,i]>0])\n",
    "    test_size = int(test_ratio * len(rated_items_by_user))\n",
    "    test_indices = np.random.randint(0, len(rated_items_by_user), test_size)\n",
    "    withheld_items = rated_items_by_user[test_indices]\n",
    "    original_user_profile = np.copy(dataMat[user])\n",
    "    dataMat[user, withheld_items] = 0 # So that the withheld test items is not used in the rating estimation below\n",
    "    error_u = 0.0\n",
    "    count_u = len(withheld_items)\n",
    "\n",
    "    # Compute absolute error for user u over all test items\n",
    "    for item in withheld_items:\n",
    "        # Estimate rating on the withheld item\n",
    "        estimatedScore = estMethod(dataMat, user, simMeas, item)\n",
    "        error_u = error_u + abs(estimatedScore - original_user_profile[item])\n",
    "\n",
    "    # Now restore ratings of the withheld items to the user profile\n",
    "    for item in withheld_items:\n",
    "        dataMat[user, item] = original_user_profile[item]\n",
    "\n",
    "    # Return sum of absolute errors and the count of test cases for this user\n",
    "    # Note that these will have to be accumulated for each user to compute MAE\n",
    "    return error_u, count_u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb2404fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataMat, test_ratio, estMethod):\n",
    "    # Write this function to iterate over all users and for each perform evaluation by calling\n",
    "    # the above cross_validate_user function on each user. MAE will be the ratio of total error \n",
    "    # across all test cases to the total number of test cases, for all users\n",
    "    absolute_error = 0\n",
    "    cnt_testcases = 0\n",
    "    \n",
    "    for num in range(dataMat.shape[0]): # iterate through the user rows of the data set\n",
    "        \n",
    "        if estMethod == 'StandEst':\n",
    "            error_u, count_u = cross_validate_user(dataMat, num, test_ratio, standEst)\n",
    "            absolute_error += error_u\n",
    "            cnt_testcases += count_u\n",
    "            \n",
    "        if estMethod == 'svdEst':\n",
    "            error_u, count_u = cross_validate_user(dataMat, num, test_ratio, svdEst)\n",
    "            absolute_error += error_u\n",
    "            cnt_testcases += count_u\n",
    "    \n",
    "#     if cnt_testcases == 0:\n",
    "#         MAE = 0\n",
    "#     else:\n",
    "        MAE = absolute_error/cnt_testcases\n",
    "            \n",
    "    print('Mean Absoloute Error for ',estMethod,' : ', MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fda059",
   "metadata": {},
   "source": [
    "#### Using the test function to perform an evaluation (with 20% test-ratio for each user) comparing MAE results using standard item-based collaborative filtering (based on the rating prediction function \"standEst\") with results using the SVD-based version of the rating item-based CF (using \"svdEst\" as the prediction engine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af77eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Mean Absoloute Error for  StandEst  :  3.683889553965739\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "test(modified_jester_data, 0.2, 'StandEst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f34334",
   "metadata": {},
   "source": [
    "<p><strong>This shows us how accurate we intend to be in our evaluations; the lowest error is going to be below or above 3.68. </strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae41a1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Mean Absoloute Error for  svdEst  :  3.6576755551824065\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "test(modified_jester_data, 0.2, 'svdEst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6b4756",
   "metadata": {},
   "source": [
    "<p><strong>This shows us how accurate we intend to be in our evaluations; the lowest error is going to be below or above 3.66. </strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671f8564",
   "metadata": {},
   "source": [
    "#### A function \"print_most_similar_jokes\" which takes the jokes ratings data, a query , a query joke id, a parameter k for the number of nearest neighbors, and a similarity metric function, and prints the text of the query joke as well as the texts of the top k most similar jokes based on user ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7873396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_similar_jokes(dataMat, jokes, queryJoke, k, metric=pearsSim):\n",
    "    print('Joke Id %s\\n \\n%s' %(queryJoke, jokes[queryJoke]))\n",
    "    print('\\n\\nThe Top %s recommended jokes are:' %k)\n",
    "    \n",
    "    jokeList = []\n",
    "    transposedDataSet = dataMat.T\n",
    "    \n",
    "    #  derive the shape of the array and get jokes\n",
    "    jokesColumn = transposedDataSet.shape[0]\n",
    "    # print('Number Of Jokes extracted: %s\\n' %jokesColumn)\n",
    "        \n",
    "    for num in range(jokesColumn):\n",
    "        similarity = metric(transposedDataSet[queryJoke], transposedDataSet[num])\n",
    "        # sim = [similarity, num]\n",
    "        jokeList.append([similarity, num])\n",
    "        \n",
    "    jokeList.sort()\n",
    "    \n",
    "\n",
    "    for num in range(len(jokeList[0:k])):\n",
    "        print('\\n %s' %(jokes[jokeList[num][1]]))\n",
    "        print('')\n",
    "        print('---'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef7c4cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_jester_data.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f759abad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke Id 5\n",
      " \n",
      "Bill & Hillary are on a trip back to Arkansas. They're almost out of gas so Bill pulls into a service station on the outskirts of town. The attendant runs out of the station to serve them when Hillary realizes it's an old boyfriend from high school. She and the attendant chat as he gases up their car and cleans the windows. Then they all say good-bye. As Bill pulls the car onto the road he turns to Hillary and says 'Now aren't you glad you married me and not him ? You could've been the wife of a grease monkey !' To which Hillary replied 'No Bill. If I would have married him you'd be pumping gas and he would be the President !'\n",
      "\n",
      "\n",
      "The Top 10 recommended jokes are:\n",
      "\n",
      " Q:  What did the blind person say when given some matzah?A:  Who the hell wrote this?\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      " Q. Did you hear about the dyslexic devil worshipper? A. He sold his soul to Santa.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      " They asked the Japanese visitor if they have elections in his country.  \"Every Morning\" he answers.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      " A dog walks into Western Union and asks the clerk to send a telegram. He fills out a form on which he writes down the telegram he wishes to send: \"Bow wow wow Bow wow wow.\"The clerk says \"You can add another 'Bow wow' for the same price.\"The dog responded \"Now wouldn't that sound a little silly?\"\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      " Q. What is orange and sounds like a parrot?  A. A carrot.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      " How many feminists does it take to screw in a light bulb?That's not funny.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      " How many men does it take to screw in a light bulb? One...men will screw anything.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      " What's the difference between a MacIntosh and anEtch-A-Sketch? You don't have to shake the Mac to clear the screen.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      " A guy goes into confession and says to the priest \"Father I'm 80 years old widower with 11 grandchildren. Last night I met two beautiful flight attendants. They took me home and I made love to both of them. Twice.\"The priest said: \"Well my son when was the last time you were in confession?\" \"Never Father I'm Jewish.\" \"So then why are you telling me?\" \"I'm telling everybody.\"\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      " Q. What's O. J. Simpson's Internet address? A.\tSlash slash backslash slash slash escape.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_most_similar_jokes(modified_jester_data, jokes, 5, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmdpy37",
   "language": "python",
   "name": "cmdpy37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
